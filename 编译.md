## InferenceHelper的下载

打开一个Git bash窗口参照[InferenceHelper_Sample](https://github.com/iwatake2222/InferenceHelper_Sample)页面描述方式将代码下载下来：
~~~bash
# 下载Sample代码
git clone https://github.com/iwatake2222/InferenceHelper_Sample
cd InferenceHelper_Sample
git submodule update --init
# 下载子模块代码已经预编译的文件
sh InferenceHelper/third_party/download_prebuilt_libraries.sh
# (Optioal)下载资源文件，主要是图片，模型文件等
sh ./download_resource.sh
~~~

由于国内IP连接Github上的tensorflow等项目十分慢，甚至无法下载，可使用[Google Colab](https://colab.research.google.com/drive/1R6t0Cj0pDGdIpFdT9tZumWYrTAgR0HC6)帮助下载，先加载到Google的云服务器上，然后再将`InferenceHelper_Sample`打包下载。

## 编译
在Linux系统上，可直接使用demo的编译指令进行(未测试)：
~~~bash
cd pj_cls_mobilenet_v2
mkdir -p build && cd build
cmake .. -DINFERENCE_HELPER_ENABLE_MNN=on
make
./main
~~~

在Windows上可借助`Cmake-gui`工具进行编译
 - `Where is the source code`: 放需要编译的项目，如`path-to-InferenceHelper_Sample/pj_cls_mobilenet_v2`
 - `Where to build the binaries` : 放编译文件的地址，如`path-to-InferenceHelper_Sample/pj_cls_mobilenet_v2/build`
 - 然后点击`Configure`，在可选参数中选择需要的，如使用tflite，则需要勾选`INFERENCE_HELPER_ENABLE_TFLITE`
 - 点击`Generate`，下方显示生成成功以后，可以`Open Project`打开项目。生成项目即可得到`main.exe`可执行文件
 - 将`main`项目设置为启动项目，则可以对项目进行调试

原仓库中要求OpenCV版本>4.0，Visual Studio 2019。实际使用中发现使用OpenCV==3.4.1也是可以的，VS2015版本也是适用的。